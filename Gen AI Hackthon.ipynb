{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c931dffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: spacy in c:\\programdata\\anaconda3\\lib\\site-packages (3.5.4)\n",
      "Requirement already satisfied: sklearn in c:\\programdata\\anaconda3\\lib\\site-packages (0.0.post5)\n",
      "Requirement already satisfied: transformers in c:\\programdata\\anaconda3\\lib\\site-packages (4.30.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\850066812\\appdata\\roaming\\python\\python39\\site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\850066812\\appdata\\roaming\\python\\python39\\site-packages (1.25.0)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: seaborn in c:\\programdata\\anaconda3\\lib\\site-packages (0.11.2)\n",
      "Collecting reportlab\n",
      "  Downloading reportlab-4.0.4-py3-none-any.whl (1.9 MB)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.10.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\850066812\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.10.10)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\850066812\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\850066812\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\850066812\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (1.7.1)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-10.0.0-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "Requirement already satisfied: six in c:\\users\\850066812\\appdata\\roaming\\python\\python39\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\850066812\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2021.10.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.22.4-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\850066812\\appdata\\roaming\\python\\python39\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Installing collected packages: numpy, pillow, reportlab\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.0\n",
      "    Uninstalling numpy-1.25.0:\n",
      "      Successfully uninstalled numpy-1.25.0\n",
      "  Rolling back uninstall of numpy\n",
      "  Moving to c:\\users\\850066812\\appdata\\roaming\\python\\python39\\scripts\\f2py.exe\n",
      "   from C:\\Users\\850066812\\AppData\\Local\\Temp\\pip-uninstall-40__45a2\\f2py.exe\n",
      "  Moving to c:\\users\\850066812\\appdata\\roaming\\python\\python39\\site-packages\\numpy-1.25.0.dist-info\\\n",
      "   from C:\\Users\\850066812\\AppData\\Roaming\\Python\\Python39\\site-packages\\~umpy-1.25.0.dist-info\n",
      "  Moving to c:\\users\\850066812\\appdata\\roaming\\python\\python39\\site-packages\\numpy\\\n",
      "   from C:\\Users\\850066812\\AppData\\Roaming\\Python\\Python39\\site-packages\\~umpy\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\ProgramData\\\\Anaconda3\\\\Lib\\\\site-packages\\\\numpy\\\\LICENSE.txt'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install nltk spacy sklearn transformers pandas numpy matplotlib seaborn reportlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7574a62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting reportlab\n",
      "  Using cached reportlab-4.0.4-py3-none-any.whl (1.9 MB)\n",
      "Collecting pillow>=9.0.0\n",
      "  Using cached Pillow-10.0.0-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "Installing collected packages: pillow, reportlab\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 8.4.0\n",
      "    Uninstalling Pillow-8.4.0:\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\pil\\\\BdfFontFile.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install reportlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f09ea636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from reportlab.pdfgen import canvas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f760ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def preprocess_text(document):\n",
    "   \n",
    "    document = document.lower()\n",
    "    document = re.sub(r\"[^a-zA-Z0-9]\", \" \", document)\n",
    "    # Tokenize the document into individual words\n",
    "    tokens = word_tokenize(document)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Join the tokens back into a single string\n",
    "    preprocessed_text = \" \".join(tokens)\n",
    "    return preprocessed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3d9bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "def validate_document(document):\n",
    "    # Load the spaCy language model\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    # Initialize the matcher\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    # Define validation patterns\n",
    "    pattern1 = [{\"POS\": \"VERB\"}, {\"POS\": \"NOUN\"}]  # Example pattern: verb followed by noun\n",
    "    # Add more patterns as per your validation rules\n",
    "\n",
    "    # Add validation patterns to the matcher\n",
    "    matcher.add(\"ValidationPattern1\", None, pattern1)\n",
    "    # Add more patterns to the matcher\n",
    "\n",
    "    # Tokenize the document\n",
    "    doc = nlp(document)\n",
    "\n",
    "    # Perform validation using the matcher\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    # Extract validation results\n",
    "    validation_results = []\n",
    "    for match_id, start, end in matches:\n",
    "        match_text = doc[start:end].text\n",
    "        validation_results.append(match_text)\n",
    "\n",
    "    return validation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb81183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_validation_report(validation_results):\n",
    "    # Count the number of validation results\n",
    "    num_results = len(validation_results)\n",
    "\n",
    "    # Generate the report header\n",
    "    report = f\"Legal Document Validation Report\\n\"\n",
    "    report += f\"Total Validation Results: {num_results}\\n\\n\"\n",
    "\n",
    "    # Generate the report body with validation details\n",
    "    if num_results > 0:\n",
    "        report += \"Validation Results:\\n\"\n",
    "        for i, result in enumerate(validation_results, start=1):\n",
    "            report += f\"{i}. {result}\\n\"\n",
    "    else:\n",
    "        report += \"No validation issues found. The document is valid.\\n\"\n",
    "\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b6a280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m documents \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]  \u001b[38;5;66;03m# List of text documents\u001b[39;00m\n\u001b[0;32m     31\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]  \u001b[38;5;66;03m# List of corresponding labels (e.g., valid/invalid)\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m trained_model, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(documents, labels)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(documents, labels):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Split the dataset into training and testing sets\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Create a TF-IDF vectorizer to convert text documents into numerical features\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2175\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2172\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2174\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2175\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2176\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1857\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   1854\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   1856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1857\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1858\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1859\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1860\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size,\n\u001b[0;32m   1861\u001b[0m                                             train_size)\n\u001b[0;32m   1862\u001b[0m     )\n\u001b[0;32m   1864\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=1, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_model(documents, labels):\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(documents, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create a TF-IDF vectorizer to convert text documents into numerical features\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "    X_test_vectorized = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Initialize the logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train_vectorized, y_train)\n",
    "    \n",
    "    # Predict the labels for the testing data\n",
    "    y_pred = model.predict(X_test_vectorized)\n",
    "    \n",
    "    # Calculate the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return model, accuracy\n",
    "\n",
    "# Example usage\n",
    "documents = [...]  # List of text documents\n",
    "labels = [...]  # List of corresponding labels (e.g., valid/invalid)\n",
    "\n",
    "trained_model, accuracy = train_model(documents, labels)\n",
    "print(f\"Model accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ba44eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the file path: C:\\Users\\850066812\\OneDrive - Genpact\\Desktop\\Aha Factor\\Supply chain Management\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\850066812\\\\OneDrive - Genpact\\\\Desktop\\\\Aha Factor\\\\Supply chain Management'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(validation_report)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 24\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the file path: \u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Prompt the user to enter the file path\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      6\u001b[0m         document \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\850066812\\\\OneDrive - Genpact\\\\Desktop\\\\Aha Factor\\\\Supply chain Management'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load the legal document from a local file\n",
    "    file_path = input(\"Enter the file path: \")  # Prompt the user to enter the file path\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            document = file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found. Please check the file path and try again.\")\n",
    "        return\n",
    "\n",
    "    # Preprocess the document\n",
    "    preprocessed_text = preprocess_text(document)\n",
    "\n",
    "    # Validate the document\n",
    "    validation_results = validate_document(preprocessed_text)\n",
    "\n",
    "    # Generate the validation report\n",
    "    validation_report = generate_validation_report(validation_results)\n",
    "\n",
    "    # Print or save the validation report\n",
    "    print(validation_report)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86ecd57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
